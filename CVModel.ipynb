{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPW18ExjQ0WpqVx2VqYobZz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7O9xCL3NsHlQ"},"outputs":[],"source":["# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n","# THEN FEEL FREE TO DELETE THIS CELL.\n","# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n","# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n","# NOTEBOOK.\n","import kagglehub\n","ashishsaxena2209_animal_image_datasetdog_cat_and_panda_path = kagglehub.dataset_download('ashishsaxena2209/animal-image-datasetdog-cat-and-panda')\n","\n","print('Data source import complete.')\n"]},{"cell_type":"code","source":["import os\n","import glob\n","from skimage.io import imread\n","from skimage.transform import resize, rotate\n","from skimage.feature import hog\n","from skimage.color import rgb2gray, rgb2hsv\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Define the correct dataset path\n","dataset_path = '/root/.cache/kagglehub/datasets/ashishsaxena2209/animal-image-datasetdog-cat-and-panda/versions/1/animals'\n","\n","# Define categories\n","categories = ['cats', 'dogs', 'panda']\n","\n","# Initialize lists for images and labels\n","animal_images = []\n","animal_labels = []\n","\n","# Load images with data augmentation\n","for animal in categories:\n","    folder_path = os.path.join(dataset_path, animal)\n","    for image_path in glob.glob(f'{folder_path}/*.jpg'):\n","        try:\n","            image = imread(image_path)\n","            image = resize(image, (128, 64))  # Resize images to uniform size\n","\n","            # Check if the image is RGB (3 channels), if not, convert to 3 channels\n","            if image.ndim == 2:  # If the image is grayscale (only one channel)\n","                image = np.stack([image] * 3, axis=-1)  # Convert to a 3-channel image by repeating the grayscale image\n","            elif image.shape[2] != 3:  # If the image does not have 3 channels\n","                raise ValueError(f\"Unexpected number of channels: {image.shape[2]} in {image_path}\")\n","\n","            # Data augmentation: Rotate and flip\n","            image_rotated = rotate(image, angle=15)\n","            image_flipped = np.fliplr(image)\n","\n","            # Convert images to grayscale and add to dataset\n","            image_gray = rgb2gray(image)\n","            image_rotated_gray = rgb2gray(image_rotated)\n","            image_flipped_gray = rgb2gray(image_flipped)\n","\n","            animal_images.extend([image_gray, image_rotated_gray, image_flipped_gray])\n","            animal_labels.extend([animal, animal, animal])\n","        except Exception as e:\n","            print(f\"Error loading {image_path}: {e}\")\n","\n","# Check if images were loaded successfully\n","print(f\"Loaded {len(animal_images)} images and {len(animal_labels)} labels.\")\n","\n","# If no images are loaded, stop execution\n","if len(animal_images) == 0:\n","    raise ValueError(\"No images found. Please check your dataset path and structure.\")\n","\n","# Extract HOG features from grayscale images\n","hog_features = [\n","    hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n","    for image in animal_images\n","]\n","hog_features = np.array(hog_features)\n","\n","# Encoding labels\n","label_encoder = LabelEncoder()\n","encoded_labels = label_encoder.fit_transform(animal_labels)\n","\n","# Split dataset\n","X_train, X_test, y_train, y_test = train_test_split(hog_features, encoded_labels, test_size=0.2, random_state=42)\n","\n","# Grid search for optimal KNN parameters (using n_neighbors)\n","param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n","grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters found by grid search\n","print(f\"Best parameters: {grid_search.best_params_}\")\n","\n","# Train with the best parameters\n","knn_clf = grid_search.best_estimator_\n","y_pred = knn_clf.predict(X_test)\n","\n","# Print classification report\n","print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"],"metadata":{"id":"MvpFIsOksNr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from PIL import Image\n","import numpy as np\n","from skimage.feature import hog\n","from skimage.transform import resize\n","from sklearn.neighbors import KNeighborsClassifier  # Assuming the classifier is trained\n","\n","# Set the path to the image in your Google Drive\n","image_path = '/content/drive/MyDrive/test2.jpg'  # Update this path\n","\n","# Open the image using Pillow\n","image = Image.open(image_path)\n","image = image.convert(\"RGB\")  # Ensure the image is in RGB format\n","\n","# Convert the image to a numpy array\n","image_np = np.array(image)\n","\n","# Resize the image to the same dimensions used during training (128x64)\n","image_resized = resize(image_np, (128, 64))\n","\n","# Extract HOG features\n","hog_features = hog(image_resized, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False, channel_axis=-1)\n","\n","# Assuming knn_clf is the trained KNN model\n","prediction = knn_clf.predict([hog_features])\n","\n","# Print the predicted class\n","print(f\"Predicted class: {prediction}\")\n"],"metadata":{"id":"MgGqYKMLsWlj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Part 2 for VS will not work on Colab\n","import cv2\n","import json\n","import os\n","import tkinter as tk\n","from tkinter import simpledialog\n","\n","# Initialize variables\n","drawing = False  # True if the mouse is pressed\n","ix, iy = -1, -1  # Initial coordinates\n","annotations = []\n","num_bboxes = 0  # Number of bounding boxes to draw\n","bboxes_drawn = 0  # Counter for bounding boxes drawn\n","\n","# List of classes (labels)\n","classes = ['cat', 'dog', 'panda']  # Update with your labels\n","\n","# Mouse callback function\n","def draw_rectangle(event, x, y, flags, param):\n","    global ix, iy, drawing, annotations, bboxes_drawn\n","\n","    if event == cv2.EVENT_LBUTTONDOWN:  # Mouse button pressed\n","        drawing = True\n","        ix, iy = x, y\n","\n","    elif event == cv2.EVENT_MOUSEMOVE:  # Mouse is moving\n","        if drawing:\n","            img_copy = img.copy()\n","            cv2.rectangle(img_copy, (ix, iy), (x, y), (0, 255, 0), 2)\n","            cv2.imshow(\"Image\", img_copy)\n","\n","    elif event == cv2.EVENT_LBUTTONUP:  # Mouse button released\n","        drawing = False\n","        cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), 2)\n","        cv2.imshow(\"Image\", img)\n","        print(\"Bounding box drawn!\")\n","\n","        # Ask for the label using tkinter\n","        root = tk.Tk()\n","        root.withdraw()  # Hide the main window\n","        label = simpledialog.askstring(\"Input\", f\"Enter label for this object (Available labels: {', '.join(classes)}):\")\n","        root.destroy()\n","\n","        if label in classes:\n","            annotations.append({\"label\": label, \"bbox\": [ix, iy, x, y]})\n","            print(f\"Bounding box and label saved: {label}\")\n","            bboxes_drawn += 1\n","        else:\n","            print(\"Invalid label! Bounding box not saved.\")\n","\n","# Load image\n","image_name = 'test2.jpg'  # Update with the correct image name\n","image_path = os.path.join(os.getcwd(), image_name)\n","img = cv2.imread(image_path)\n","\n","if img is None:\n","    print(\"Image not found! Check the path.\")\n","else:\n","    # Ask for the number of bounding boxes to draw\n","    root = tk.Tk()\n","    root.withdraw()  # Hide the main window\n","    num_bboxes = simpledialog.askinteger(\"Input\", \"Enter the number of bounding boxes to draw:\")\n","    root.destroy()\n","\n","    if num_bboxes is None or num_bboxes <= 0:\n","        print(\"Invalid number of bounding boxes. Exiting.\")\n","    else:\n","        # Create a window and set the mouse callback\n","        cv2.namedWindow(\"Image\")\n","        cv2.setMouseCallback(\"Image\", draw_rectangle)\n","\n","        # Show the image and wait for user input\n","        print(\"Press 'q' to quit and save annotations.\")\n","        while True:\n","            cv2.imshow(\"Image\", img)\n","            key = cv2.waitKey(10) & 0xFF  # Increase wait time to 10ms\n","            if key == ord('q'):  # Press 'q' to quit\n","                break\n","            if cv2.getWindowProperty(\"Image\", cv2.WND_PROP_VISIBLE) < 1:  # Handle window close event\n","                break\n","            if bboxes_drawn >= num_bboxes:  # Stop when the specified number of bounding boxes are drawn\n","                break\n","\n","        # Save annotations as JSON\n","        annotations_path = os.path.join(os.getcwd(), 'annotations.json')\n","        with open(annotations_path, 'w') as f:\n","            json.dump(annotations, f)\n","\n","        print(f\"Annotations saved to {annotations_path}\")\n","        cv2.destroyAllWindows()"],"metadata":{"id":"tm6n8TFjsbfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# also part 2 next part\n","import cv2\n","import json\n","import os\n","\n","# Load annotations from JSON file\n","annotations_path = os.path.join(os.getcwd(), 'annotations.json')\n","with open(annotations_path, 'r') as f:\n","    annotations = json.load(f)\n","\n","# Load image\n","image_name = 'test2.jpg'  # Update with the correct image name\n","image_path = os.path.join(os.getcwd(), image_name)\n","img = cv2.imread(image_path)\n","\n","if img is None:\n","    print(\"Image not found! Check the path.\")\n","else:\n","    # Draw bounding boxes on the image\n","    for annotation in annotations:\n","        label = annotation['label']\n","        bbox = annotation['bbox']\n","        x1, y1, x2, y2 = bbox\n","        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n","\n","    # Display the image with bounding boxes\n","    cv2.imshow(\"Detected Objects\", img)\n","    print(\"Press 'q' to quit.\")\n","    while True:\n","        key = cv2.waitKey(10) & 0xFF\n","        if key == ord('q'):  # Press 'q' to quit\n","            break\n","        if cv2.getWindowProperty(\"Detected Objects\", cv2.WND_PROP_VISIBLE) < 1:  # Handle window close event\n","            break\n","\n","    cv2.destroyAllWindows()"],"metadata":{"id":"ayiYHqnYslEp"},"execution_count":null,"outputs":[]}]}